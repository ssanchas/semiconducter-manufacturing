{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Import libraries and Packages \n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from pandas import Series\n", "from sklearn.linear_model import Lasso\n", "from sklearn.model_selection import train_test_split\n", "\n", "%matplotlib inline\n", "\n", "###########################################################\n", "\n", "# Loading Data-Set\n", "label = pd.read_csv(\"/Users/Mahyar/SECOM/secom_labels.txt\", delim_whitespace=True, header=None)\n", "features = pd.read_csv(\"/Users/Mahyar/SECOM/secom_data.txt\", delim_whitespace=True,header=None)\n", "\n", "features = features.rename(columns={features.columns[i]: 'F'+ str(i) for i in range (590)}) # adding name to feature columns\n", "label = label.rename(columns={0: 'L0', 1 :'date'})   # adding name to label column\n", "\n", "############################################################\n", "\n", "# Concatinating to separate files\n", "df = pd.concat([features,label],axis=1, ignore_index=False)\n", "#print(df.head()) # Preliminary inspection of data-set\n", "#print(df.shape) # Preliminary inspection of data-set\n", "#print(df.index) # Preliminary inspection of data-set\n", "\n", "# Dropping columns with more than 10% missing data\n", "df = df.dropna(thresh=len(df) - int(0.1 * len(df)), axis=1)\n", "df = df.fillna(df.median())\n", "df.L0.replace(-1,0, inplace=True) # Converting label column to binary [0,1]\n", "\n", "# Building label vectore (y) and feature matrix(X)\n", "y = df['L0']\n", "X = df.drop(['L0','date'], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Employing Lasso regularization approach to reduce feature matrix dimenssion\n", "lasso = Lasso(alpha=0.2,normalize=False)\n", "lasso_coef = lasso.fit(X, y).coef_\n", "print('Total number of remaining features:')\n", "print(len(lasso_coef[lasso_coef!=0.0]))\n", "\n", "# Making a list from selected features\n", "val = lasso_coef[lasso_coef!=0.0]\n", "key, = np.where(lasso_coef!=0.0)\n", "feature_list = X.columns[key]\n", "val_plt = np.multiply(val,1000)\n", "feature_list = feature_list.tolist()\n", "feature_column = key.tolist()\n", "val = val.tolist()\n", "print('List of selected features via Lasso dimenssion reduction:')\n", "print(feature_list)\n", "\n", "# revising feature matrix based on LASSO features reduction\n", "X = X[feature_list]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Making correlation coefficients pair plot of all feature in order to identify degenrate features\n", "plt.figure(figsize=(25,25))\n", "df1 = pd.concat([X,y],axis=1, ignore_index=False) \n", "ax = plt.axes()\n", "corr = df1.corr()\n", "sns.heatmap(corr, vmax=1,vmin=-1, square=True, annot=False, cmap='Spectral',linecolor=\"white\", linewidths=0.01, ax=ax)\n", "plt.xticks(rotation=90,fontweight=\"bold\", size=15) \n", "plt.yticks(rotation=0,fontweight=\"bold\", size=15) \n", "plt.title('Correlation Coefficient Pair Plot', fontweight=\"bold\", size=18)\n", "plt.savefig('pcp.png')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Making box plot to explore features variations and outliers\n", "plt.figure(figsize=(16,8))\n", "sns.set()\n", "sns.boxplot(data=X, orient=\"v\", palette=\"Set2\")\n", "plt.xlabel('Features',fontweight=\"bold\", size=12)\n", "plt.ylabel('Variation',fontweight=\"bold\", size=12)\n", "plt.title('Box Plot of Selected Features', fontweight=\"bold\", size=18)\n", "plt.yscale('symlog', nonposy='clip')\n", "plt.xticks(rotation=90)\n", "plt.savefig('BoxPlot.png');plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Exploratory Data Analysis\n", "# Plotting total products against failed product in histogram format  \n", "bins = 30\n", "for feature in feature_list:\n", "    tf = feature\n", "    plt.figure()\n", "    plt.hist(df1[tf], bins = bins, color='m',label = 'Total',alpha=0.5)\n", "    plt.hist(df1[tf][df1['L0'] == 1], bins = bins, color='b',label = 'Fail')\n", "\n", "    plt.xlabel(tf);plt.ylabel('Production')\n", "    plt.title('Feature ID:'+tf,fontweight=\"bold\", size=12)\n", "    plt.yscale('log')\n", "\n", "    plt.legend();plt.savefig(tf+'.png');\n", "    plt.close();\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Statistical Analysis & Hypothesis Testing\n", "num_replica = 3000\n", "bs_replica = np.empty(num_replica)\n", "ht_feature = 'F484'\n", "threshold = 680\n", "\n", "lower_range = df1[(df1[ht_feature]>threshold) ]\n", "higher_range = df1[(df1[ht_feature]<=threshold)]\n", "\n", "lower_range_ratio = len(lower_range[lower_range['L0'] == 1])/len(lower_range)\n", "higher_range_ratio = len(higher_range[higher_range['L0'] == 1])/len(higher_range)\n", "ratio_diff = higher_range_ratio-lower_range_ratio\n", "\n", "print('Higher fail ratio:',\"%.3f\" % higher_range_ratio)\n", "print('Lower fail ration:',\"%.3f\" % lower_range_ratio)\n", "print('Ratio difference:', \"%.3f\" % ratio_diff)\n", "\n", "# Bootstrapping\n", "for i in range(num_replica):\n", "    lr_bs = lower_range.sample(frac=1,replace=True)\n", "    hr_bs = higher_range.sample(frac=1,replace=True)\n", "    \n", "    lr_bs_r = len(lr_bs[lr_bs['L0'] == 1])/len(lr_bs)\n", "    hr_bs_r = len(hr_bs[hr_bs['L0'] == 1])/len(hr_bs)\n", "    ratio_diff_bs = hr_bs_r - lr_bs_r\n", "    bs_replica[i] = ratio_diff_bs  \n", "\n", "\n", "# Histogram plot    \n", "plt.hist(bs_replica, bins=20)\n", "plt.axvline(ratio_diff, color='r', linestyle='dashed', linewidth=3)\n", "plt.xlabel('Yield Ratio Difference',fontweight=\"bold\", size=12)\n", "plt.savefig('Hypothesis.png');\n", "plt.show()   \n", "\n", "# Calculating P-value\n", "print('Mean ratio decrease:',\"%.3f\" % np.mean(bs_replica))\n", "print('95% Confidence interval:', (np.percentile(bs_replica,[2.5,97.5])))\n", "print('P-value:', np.sum(bs_replica > (ratio_diff))/num_replica)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Preparing data for time series analysis\n", "# Concatinating two separate files\n", "df2 = pd.concat([features,label],axis=1, ignore_index=False)\n", "\n", "# Converting to time series format\n", "df2.date = pd.to_datetime(df2.date)\n", "df2.set_index('date', inplace=True)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Resampling yield data based on daily information \n", "failed_product = df2.L0[df2['L0']==1].resample('D').count()\n", "total_product = df2.L0[df2['L0']==-1].resample('D').count()\n", "\n", "failed_ratio = failed_product * 100 / total_product\n", "failed_ratio = failed_ratio.dropna()\n", "\n", "# Visualizaion of daily production failed ratio\n", "sns.set()\n", "\n", "failed_ratio.plot(style='bo-',MarkerSize=4, LineWidth = 0.6, figsize=(15,5))\n", "\n", "plt.xlabel('Date', fontweight=\"bold\", size=12)\n", "plt.ylabel('Failed Ratio (%)', fontweight=\"bold\", size=12)\n", "plt.grid(True);plt.savefig('100Days.png')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Indexing dates with more than 50% failed ratio\n", "date_index = failed_ratio[failed_ratio >= 50]\n", "\n", "# Plotting F484 for date_index\n", "df2['F484'].loc['2008-07-21'].hist(alpha=0.7, label = '2008-07-21')\n", "df2['F484'].loc['2008-07-29'].hist(alpha=0.7, label = '2008-07-29')\n", "df2['F484'].loc['2008-07-30'].hist(alpha=0.7, label = '2008-07-30')\n", "df2['F484'].loc['2008-10-08'].hist(alpha=0.7, label = '2008-10-08')\n", "plt.axvline(680, color='r', linestyle='dashed', linewidth=3) # Thresold in hypothesis testing (Previouse section)\n", "plt.xlabel('F484', fontweight=\"bold\", size=12)\n", "plt.legend()\n", "plt.savefig('F484_Worst.png')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["#########################################################\n", "# Claculating default Ratio\n", "passed = len(df[df['L0']==0])\n", "failed = len(df[df['L0']==1])\n", "ratio = float(failed/(passed+failed))\n", "print('Number of passed sample:', passed)\n", "print('Number of failed sample:', failed)\n", "print('Default Ratio (failed/total) :', \"%.3f\" % ratio)\n", "\n", "#########################################################\n", "# Splitting data to train and test sets\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=42)\n", "X_test = X_test.as_matrix() # Coverting dataframe to matrix for compatibility purpose\n", "\n", "# Under-sampling of overer-represented calss (pass) \n", "from imblearn.under_sampling import RandomUnderSampler\n", "rus = RandomUnderSampler(random_state=0)\n", "X_us, y_us = rus.fit_sample(X_train, y_train)\n", "\n", "print('########################################')\n", "print('Size of training data-set:', X_train.shape)\n", "print('Size of under sampling data_set:', X_us.shape)\n", "\n", "# Over-sampling of under-represented calss (fail)\n", "from imblearn.over_sampling import RandomOverSampler\n", "ros = RandomOverSampler(random_state=0)\n", "X_os, y_os = ros.fit_sample(X_train, y_train)\n", "print('Size of overer sampling data_set:', X_os.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Import ML Libraries \n", "\n", "import xgboost as xgb\n", "from xgboost.sklearn import XGBClassifier\n", "from sklearn import cross_validation, metrics   #Additional scklearn functions\n", "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n", "from sklearn.metrics import roc_curve, auc,roc_auc_score\n", "from sklearn.metrics import classification_report\n", "from matplotlib.pylab import rcParams\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "rcParams['figure.figsize'] = 12, 4"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# XGB Model\n", "\n", "def xgb_model(alg, X_matrix, y_vector, test_matrix, test_vector, useTrainCV=True, useTestSet = False, cv_folds=5, early_stopping_rounds=50):\n", "    \n", "    if useTrainCV:\n", "        xgb_param = alg.get_xgb_params()\n", "        xgtrain = xgb.DMatrix(X_matrix, y_vector)\n", "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n", "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n", "        alg.set_params(n_estimators=cvresult.shape[0])\n", "    \n", "    #Fit the algorithm on the data\n", "    alg.fit(X_matrix, y_vector, eval_metric='auc')   \n", "    \n", "    #Predict training set:\n", "    dtrain_predictions = alg.predict(X_matrix)\n", "    dtrain_predprob = alg.predict_proba(X_matrix)[:,1]\n", "    #Print model report:\n", "    print (\"\\nModel Report on Training Set\")\n", "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_vector, dtrain_predictions))\n", "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_vector, dtrain_predprob))\n", "    # Determine the false positive and true positive rates\n", "    fpr_train, tpr_train, _ = roc_curve(y_vector, dtrain_predprob)\n", "    # Plot of a ROC curve for a specific class\n", "    plt.figure()\n", "    plt.plot(fpr_train, tpr_train, label='Training ROC curve (area = %0.2f)' % metrics.roc_auc_score(y_vector, dtrain_predprob))\n", "       \n", "    ############################################################    \n", "    if useTestSet:   \n", "        #Predict test set:\n", "        dtest_predictions = alg.predict(test_matrix)\n", "        dtest_predprob = alg.predict_proba(test_matrix)[:,1] \n", "        #Print model report:\n", "        print (\"\\nModel Report on Test Set\")\n", "        print (\"Accuracy : %.4g\" % metrics.accuracy_score(test_vector, dtest_predictions))\n", "        print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(test_vector, dtest_predprob))               \n", "        # Determine the false positive and true positive rates\n", "        fpr_test, tpr_test, _ = roc_curve(test_vector, dtest_predprob) \n", "        # Plot of a ROC curve for a specific class\n", "        plt.plot(fpr_test, tpr_test, label='Test ROC curve (area = %0.2f)' % metrics.roc_auc_score(test_vector, dtest_predprob))\n", "              \n", "    ############################################################    \n", "    plt.plot([0, 1], [0, 1], 'k--'); plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05]);\n", "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve')\n", "    plt.legend(loc=\"lower right\"); plt.savefig('ROC.png'); plt.show()\n", "\n", "    \n", "    ############################################################\n", "    # Calculating feature importance\n", "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n", "    feat_imp.plot(kind='bar', title='Feature Importances')\n", "    plt.ylabel('Feature Importance Score')\n", "    plt.savefig('Feature_Importance.png'); plt.show()    "]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# First run with default model parameters \n", "\n", "xgb1 = XGBClassifier(\n", " learning_rate =0.1,\n", " n_estimators=200,\n", " max_depth=5,\n", " min_child_weight=1,\n", " gamma=0,\n", " subsample=0.8,\n", " colsample_bytree=0.8,\n", " reg_alpha=0,\n", " reg_lambda=1,     \n", " objective= 'binary:logistic',\n", " nthread=4,\n", " scale_pos_weight=1,\n", " seed=27)\n", "xgb_model(xgb1, X_train, y_train, X_test, y_test)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning max_depth & min_child_weight (Part I)\n", "\n", "param_test1 = {\n", " 'max_depth':np.arange(3,10,2),\n", " 'min_child_weight':np.arange(1,10,2)\n", "}\n", "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=5,\n", " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n", " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch1.fit(X_train, y_train)\n", "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning max_depth & min_child_weight (Part II)\n", "param_test2 = {\n", " 'max_depth':[6,7,8]\n", " }\n", "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=200, max_depth=7,\n", " min_child_weight=9, gamma=0, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch2.fit(X_train, y_train)\n", "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning max_depth & min_child_weight (Part III)\n", "param_test3 = {\n", " 'min_child_weight':[8,9,10,11,12,13,14,15,16]\n", "}\n", "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=9, gamma=0, subsample=0.8, colsample_bytree=0.8,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch3.fit(X_train, y_train)\n", "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning gamma\n", "param_test4 = {\n", " 'gamma':[i/10.0 for i in range(0,8)]\n", "}\n", "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch4.fit(X_train, y_train)\n", "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning subsample & colsample_bytree (Part I)\n", "param_test5 = {\n", " 'subsample':[i/10.0 for i in range(6,10)],\n", " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n", "}\n", "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0.4, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch5.fit(X_train, y_train)\n", "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning subsample & colsample_bytree (Part II)\n", "param_test6 = {\n", " 'subsample':[i/100.0 for i in range(70,95,5)],\n", " 'colsample_bytree':[i/100.0 for i in range(70,95,5)]\n", "}\n", "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0.4, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch6.fit(X_train, y_train)\n", "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning reg_alpha\n", "param_test7 = {\n", " 'reg_alpha':[0.0, 0.1,0.2,0.3,0.4,0.5]\n", "}\n", "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0.4, subsample=0.8, colsample_bytree=0.75,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch7.fit(X_train, y_train)\n", "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["X_train = X_train.as_matrix()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["xgb2 = XGBClassifier(\n", " learning_rate =0.1,\n", " n_estimators=200,\n", " max_depth=6,\n", " min_child_weight=14,\n", " gamma=0.4,\n", " subsample=0.8,\n", " colsample_bytree=0.75,\n", " reg_alpha=0.5,\n", " reg_lambda=1,   \n", " objective= 'binary:logistic',\n", " nthread=4,\n", " scale_pos_weight=1,\n", " seed=27)\n", "xgb_model(xgb2, X_train, y_train, X_test, y_test, useTestSet = True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Import libraries and Packages \n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from pandas import Series\n", "from sklearn.linear_model import Lasso\n", "from sklearn.model_selection import train_test_split\n", "\n", "%matplotlib inline\n", "\n", "###########################################################\n", "\n", "# Loading Data-Set\n", "label = pd.read_csv(\"/Users/Mahyar/SECOM/secom_labels.txt\", delim_whitespace=True, header=None)\n", "features = pd.read_csv(\"/Users/Mahyar/SECOM/secom_data.txt\", delim_whitespace=True,header=None)\n", "\n", "features = features.rename(columns={features.columns[i]: 'F'+ str(i) for i in range (590)}) # adding name to feature columns\n", "label = label.rename(columns={0: 'L0', 1 :'date'})   # adding name to label column\n", "\n", "############################################################\n", "\n", "# Concatinating to separate files\n", "df = pd.concat([features,label],axis=1, ignore_index=False)\n", "#print(df.head()) # Preliminary inspection of data-set\n", "#print(df.shape) # Preliminary inspection of data-set\n", "#print(df.index) # Preliminary inspection of data-set\n", "\n", "# Dropping columns with more than 10% missing data\n", "df = df.dropna(thresh=len(df) - int(0.1 * len(df)), axis=1)\n", "df = df.fillna(df.median())\n", "df.L0.replace(-1,0, inplace=True) # Converting label column to binary [0,1]\n", "\n", "# Building label vectore (y) and feature matrix(X)\n", "y = df['L0']\n", "X = df.drop(['L0','date'], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Employing Lasso regularization approach to reduce feature matrix dimenssion\n", "lasso = Lasso(alpha=0.2,normalize=False)\n", "lasso_coef = lasso.fit(X, y).coef_\n", "print('Total number of remaining features:')\n", "print(len(lasso_coef[lasso_coef!=0.0]))\n", "\n", "# Making a list from selected features\n", "val = lasso_coef[lasso_coef!=0.0]\n", "key, = np.where(lasso_coef!=0.0)\n", "feature_list = X.columns[key]\n", "val_plt = np.multiply(val,1000)\n", "feature_list = feature_list.tolist()\n", "feature_column = key.tolist()\n", "val = val.tolist()\n", "print('List of selected features via Lasso dimenssion reduction:')\n", "print(feature_list)\n", "\n", "# revising feature matrix based on LASSO features reduction\n", "X = X[feature_list]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Making correlation coefficients pair plot of all feature in order to identify degenrate features\n", "plt.figure(figsize=(25,25))\n", "df1 = pd.concat([X,y],axis=1, ignore_index=False) \n", "ax = plt.axes()\n", "corr = df1.corr()\n", "sns.heatmap(corr, vmax=1,vmin=-1, square=True, annot=False, cmap='Spectral',linecolor=\"white\", linewidths=0.01, ax=ax)\n", "plt.xticks(rotation=90,fontweight=\"bold\", size=15) \n", "plt.yticks(rotation=0,fontweight=\"bold\", size=15) \n", "plt.title('Correlation Coefficient Pair Plot', fontweight=\"bold\", size=18)\n", "plt.savefig('pcp.png')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Making box plot to explore features variations and outliers\n", "plt.figure(figsize=(16,8))\n", "sns.set()\n", "sns.boxplot(data=X, orient=\"v\", palette=\"Set2\")\n", "plt.xlabel('Features',fontweight=\"bold\", size=12)\n", "plt.ylabel('Variation',fontweight=\"bold\", size=12)\n", "plt.title('Box Plot of Selected Features', fontweight=\"bold\", size=18)\n", "plt.yscale('symlog', nonposy='clip')\n", "plt.xticks(rotation=90)\n", "plt.savefig('BoxPlot.png');plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Exploratory Data Analysis\n", "# Plotting total products against failed product in histogram format  \n", "bins = 30\n", "for feature in feature_list:\n", "    tf = feature\n", "    plt.figure()\n", "    plt.hist(df1[tf], bins = bins, color='m',label = 'Total',alpha=0.5)\n", "    plt.hist(df1[tf][df1['L0'] == 1], bins = bins, color='b',label = 'Fail')\n", "\n", "    plt.xlabel(tf);plt.ylabel('Production')\n", "    plt.title('Feature ID:'+tf,fontweight=\"bold\", size=12)\n", "    plt.yscale('log')\n", "\n", "    plt.legend();plt.savefig(tf+'.png');\n", "    plt.close();\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Statistical Analysis & Hypothesis Testing\n", "num_replica = 3000\n", "bs_replica = np.empty(num_replica)\n", "ht_feature = 'F484'\n", "threshold = 680\n", "\n", "lower_range = df1[(df1[ht_feature]>threshold) ]\n", "higher_range = df1[(df1[ht_feature]<=threshold)]\n", "\n", "lower_range_ratio = len(lower_range[lower_range['L0'] == 1])/len(lower_range)\n", "higher_range_ratio = len(higher_range[higher_range['L0'] == 1])/len(higher_range)\n", "ratio_diff = higher_range_ratio-lower_range_ratio\n", "\n", "print('Higher fail ratio:',\"%.3f\" % higher_range_ratio)\n", "print('Lower fail ration:',\"%.3f\" % lower_range_ratio)\n", "print('Ratio difference:', \"%.3f\" % ratio_diff)\n", "\n", "# Bootstrapping\n", "for i in range(num_replica):\n", "    lr_bs = lower_range.sample(frac=1,replace=True)\n", "    hr_bs = higher_range.sample(frac=1,replace=True)\n", "    \n", "    lr_bs_r = len(lr_bs[lr_bs['L0'] == 1])/len(lr_bs)\n", "    hr_bs_r = len(hr_bs[hr_bs['L0'] == 1])/len(hr_bs)\n", "    ratio_diff_bs = hr_bs_r - lr_bs_r\n", "    bs_replica[i] = ratio_diff_bs  \n", "\n", "\n", "# Histogram plot    \n", "plt.hist(bs_replica, bins=20)\n", "plt.axvline(ratio_diff, color='r', linestyle='dashed', linewidth=3)\n", "plt.xlabel('Yield Ratio Difference',fontweight=\"bold\", size=12)\n", "plt.savefig('Hypothesis.png');\n", "plt.show()   \n", "\n", "# Calculating P-value\n", "print('Mean ratio decrease:',\"%.3f\" % np.mean(bs_replica))\n", "print('95% Confidence interval:', (np.percentile(bs_replica,[2.5,97.5])))\n", "print('P-value:', np.sum(bs_replica > (ratio_diff))/num_replica)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Preparing data for time series analysis\n", "# Concatinating two separate files\n", "df2 = pd.concat([features,label],axis=1, ignore_index=False)\n", "\n", "# Converting to time series format\n", "df2.date = pd.to_datetime(df2.date)\n", "df2.set_index('date', inplace=True)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Resampling yield data based on daily information \n", "failed_product = df2.L0[df2['L0']==1].resample('D').count()\n", "total_product = df2.L0[df2['L0']==-1].resample('D').count()\n", "\n", "failed_ratio = failed_product * 100 / total_product\n", "failed_ratio = failed_ratio.dropna()\n", "\n", "# Visualizaion of daily production failed ratio\n", "sns.set()\n", "\n", "failed_ratio.plot(style='bo-',MarkerSize=4, LineWidth = 0.6, figsize=(15,5))\n", "\n", "plt.xlabel('Date', fontweight=\"bold\", size=12)\n", "plt.ylabel('Failed Ratio (%)', fontweight=\"bold\", size=12)\n", "plt.grid(True);plt.savefig('100Days.png')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Indexing dates with more than 50% failed ratio\n", "date_index = failed_ratio[failed_ratio >= 50]\n", "\n", "# Plotting F484 for date_index\n", "df2['F484'].loc['2008-07-21'].hist(alpha=0.7, label = '2008-07-21')\n", "df2['F484'].loc['2008-07-29'].hist(alpha=0.7, label = '2008-07-29')\n", "df2['F484'].loc['2008-07-30'].hist(alpha=0.7, label = '2008-07-30')\n", "df2['F484'].loc['2008-10-08'].hist(alpha=0.7, label = '2008-10-08')\n", "plt.axvline(680, color='r', linestyle='dashed', linewidth=3) # Thresold in hypothesis testing (Previouse section)\n", "plt.xlabel('F484', fontweight=\"bold\", size=12)\n", "plt.legend()\n", "plt.savefig('F484_Worst.png')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["#########################################################\n", "# Claculating default Ratio\n", "passed = len(df[df['L0']==0])\n", "failed = len(df[df['L0']==1])\n", "ratio = float(failed/(passed+failed))\n", "print('Number of passed sample:', passed)\n", "print('Number of failed sample:', failed)\n", "print('Default Ratio (failed/total) :', \"%.3f\" % ratio)\n", "\n", "#########################################################\n", "# Splitting data to train and test sets\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=42)\n", "X_test = X_test.as_matrix() # Coverting dataframe to matrix for compatibility purpose\n", "\n", "# Under-sampling of overer-represented calss (pass) \n", "from imblearn.under_sampling import RandomUnderSampler\n", "rus = RandomUnderSampler(random_state=0)\n", "X_us, y_us = rus.fit_sample(X_train, y_train)\n", "\n", "print('########################################')\n", "print('Size of training data-set:', X_train.shape)\n", "print('Size of under sampling data_set:', X_us.shape)\n", "\n", "# Over-sampling of under-represented calss (fail)\n", "from imblearn.over_sampling import RandomOverSampler\n", "ros = RandomOverSampler(random_state=0)\n", "X_os, y_os = ros.fit_sample(X_train, y_train)\n", "print('Size of overer sampling data_set:', X_os.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Import ML Libraries \n", "\n", "import xgboost as xgb\n", "from xgboost.sklearn import XGBClassifier\n", "from sklearn import cross_validation, metrics   #Additional scklearn functions\n", "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n", "from sklearn.metrics import roc_curve, auc,roc_auc_score\n", "from sklearn.metrics import classification_report\n", "from matplotlib.pylab import rcParams\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "rcParams['figure.figsize'] = 12, 4"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# XGB Model\n", "\n", "def xgb_model(alg, X_matrix, y_vector, test_matrix, test_vector, useTrainCV=True, useTestSet = False, cv_folds=5, early_stopping_rounds=50):\n", "    \n", "    if useTrainCV:\n", "        xgb_param = alg.get_xgb_params()\n", "        xgtrain = xgb.DMatrix(X_matrix, y_vector)\n", "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n", "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n", "        alg.set_params(n_estimators=cvresult.shape[0])\n", "    \n", "    #Fit the algorithm on the data\n", "    alg.fit(X_matrix, y_vector, eval_metric='auc')   \n", "    \n", "    #Predict training set:\n", "    dtrain_predictions = alg.predict(X_matrix)\n", "    dtrain_predprob = alg.predict_proba(X_matrix)[:,1]\n", "    #Print model report:\n", "    print (\"\\nModel Report on Training Set\")\n", "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_vector, dtrain_predictions))\n", "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_vector, dtrain_predprob))\n", "    # Determine the false positive and true positive rates\n", "    fpr_train, tpr_train, _ = roc_curve(y_vector, dtrain_predprob)\n", "    # Plot of a ROC curve for a specific class\n", "    plt.figure()\n", "    plt.plot(fpr_train, tpr_train, label='Training ROC curve (area = %0.2f)' % metrics.roc_auc_score(y_vector, dtrain_predprob))\n", "       \n", "    ############################################################    \n", "    if useTestSet:   \n", "        #Predict test set:\n", "        dtest_predictions = alg.predict(test_matrix)\n", "        dtest_predprob = alg.predict_proba(test_matrix)[:,1] \n", "        #Print model report:\n", "        print (\"\\nModel Report on Test Set\")\n", "        print (\"Accuracy : %.4g\" % metrics.accuracy_score(test_vector, dtest_predictions))\n", "        print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(test_vector, dtest_predprob))               \n", "        # Determine the false positive and true positive rates\n", "        fpr_test, tpr_test, _ = roc_curve(test_vector, dtest_predprob) \n", "        # Plot of a ROC curve for a specific class\n", "        plt.plot(fpr_test, tpr_test, label='Test ROC curve (area = %0.2f)' % metrics.roc_auc_score(test_vector, dtest_predprob))\n", "              \n", "    ############################################################    \n", "    plt.plot([0, 1], [0, 1], 'k--'); plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05]);\n", "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve')\n", "    plt.legend(loc=\"lower right\"); plt.savefig('ROC.png'); plt.show()\n", "\n", "    \n", "    ############################################################\n", "    # Calculating feature importance\n", "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n", "    feat_imp.plot(kind='bar', title='Feature Importances')\n", "    plt.ylabel('Feature Importance Score')\n", "    plt.savefig('Feature_Importance.png'); plt.show()    "]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# First run with default model parameters \n", "\n", "xgb1 = XGBClassifier(\n", " learning_rate =0.1,\n", " n_estimators=200,\n", " max_depth=5,\n", " min_child_weight=1,\n", " gamma=0,\n", " subsample=0.8,\n", " colsample_bytree=0.8,\n", " reg_alpha=0,\n", " reg_lambda=1,     \n", " objective= 'binary:logistic',\n", " nthread=4,\n", " scale_pos_weight=1,\n", " seed=27)\n", "xgb_model(xgb1, X_train, y_train, X_test, y_test)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning max_depth & min_child_weight (Part I)\n", "\n", "param_test1 = {\n", " 'max_depth':np.arange(3,10,2),\n", " 'min_child_weight':np.arange(1,10,2)\n", "}\n", "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=5,\n", " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n", " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch1.fit(X_train, y_train)\n", "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning max_depth & min_child_weight (Part II)\n", "param_test2 = {\n", " 'max_depth':[6,7,8]\n", " }\n", "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=200, max_depth=7,\n", " min_child_weight=9, gamma=0, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch2.fit(X_train, y_train)\n", "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning max_depth & min_child_weight (Part III)\n", "param_test3 = {\n", " 'min_child_weight':[8,9,10,11,12,13,14,15,16]\n", "}\n", "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=9, gamma=0, subsample=0.8, colsample_bytree=0.8,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch3.fit(X_train, y_train)\n", "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning gamma\n", "param_test4 = {\n", " 'gamma':[i/10.0 for i in range(0,8)]\n", "}\n", "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch4.fit(X_train, y_train)\n", "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning subsample & colsample_bytree (Part I)\n", "param_test5 = {\n", " 'subsample':[i/10.0 for i in range(6,10)],\n", " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n", "}\n", "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0.4, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch5.fit(X_train, y_train)\n", "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning subsample & colsample_bytree (Part II)\n", "param_test6 = {\n", " 'subsample':[i/100.0 for i in range(70,95,5)],\n", " 'colsample_bytree':[i/100.0 for i in range(70,95,5)]\n", "}\n", "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0.4, subsample=0.8, colsample_bytree=0.8,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch6.fit(X_train, y_train)\n", "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Tunning reg_alpha\n", "param_test7 = {\n", " 'reg_alpha':[0.0, 0.1,0.2,0.3,0.4,0.5]\n", "}\n", "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=200, max_depth=6,\n", " min_child_weight=14, gamma=0.4, subsample=0.8, colsample_bytree=0.75,reg_alpha=0, reg_lambda=1,\n", " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n", " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n", "gsearch7.fit(X_train, y_train)\n", "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["X_train = X_train.as_matrix()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["xgb2 = XGBClassifier(\n", " learning_rate =0.1,\n", " n_estimators=200,\n", " max_depth=6,\n", " min_child_weight=14,\n", " gamma=0.4,\n", " subsample=0.8,\n", " colsample_bytree=0.75,\n", " reg_alpha=0.5,\n", " reg_lambda=1,   \n", " objective= 'binary:logistic',\n", " nthread=4,\n", " scale_pos_weight=1,\n", " seed=27)\n", "xgb_model(xgb2, X_train, y_train, X_test, y_test, useTestSet = True)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}}, "nbformat": 4, "nbformat_minor": 2}